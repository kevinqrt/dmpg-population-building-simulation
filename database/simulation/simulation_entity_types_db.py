import pandas as pd
from peewee import IntegrityError
import logging
from tabulate import tabulate

import database.base.table_config as tc
from src.core.utils.helper import round_value
from database.base.database_config import drop_table, initialize_table
from database.base.models import entity_type_stats_table, run_simulation_table
from database.simulation.simulation_db import current_simulation_id
from src.core.components.entity import EntityManager


def store_entity_type_stats(formatted_data: list):
    """
    Stores entity-type-specific statistics in a separate database table.
    Expects input in the format generated by `format_entity_type_stats(...)`.

    Each row represents a single metric (stat) for a component,
    broken down by individual entity types.
    """
    drop_table(entity_type_stats_table)
    initialize_table(entity_type_stats_table)

    simulation_id = current_simulation_id()  # can be changed to a dynamic value

    rows = []
    for row in formatted_data:
        base = {
            'simulation_id': simulation_id,
            'component_type': row['Type'],
            'component_name': row['Name'],
            'stat': row['Stat']
        }

        for entity_type in EntityManager.entity_types_list:
            if entity_type in row:
                rows.append({
                    **base,
                    'entity_type': entity_type,
                    'value': round_value(row[entity_type])
                })

    if rows:
        try:
            entity_type_stats_table.insert_many(rows).execute()
        except IntegrityError as e:
            logging.error(f"Error while storing entity_type_stats: {e}")


def create_etype_pivot() -> pd.DataFrame:
    """
    Joins `run_simulation_table` with `entity_type_stats_table` into a combined pivot-style DataFrame.

    This function:
    - Loads general simulation statistics from `run_simulation_table`
    - Loads per-entity-type statistics from `entity_type_stats_table`
    - Pivots the entity-type statistics so that each entity type becomes a separate column
    - Merges the pivoted entity-type stats with the general stats on (Type, Name, Stat)
    - Returns a unified DataFrame for reporting or export

    If no entity-type statistics are available, the method returns only the general stats.
    """
    sim_id = current_simulation_id()

    # Select Fields from the run_simulation_table
    simulation_query = run_simulation_table.select(
        run_simulation_table.type,
        run_simulation_table.name,
        run_simulation_table.stat,
        run_simulation_table.value
    ).where(run_simulation_table.simulation_id == sim_id)

    # Create based on the simulation_query a pandas DataFrame
    simulation_df = pd.DataFrame(list(simulation_query.dicts()))

    # Select Fields from the entity_type_table
    entity_type_query = entity_type_stats_table.select().where(entity_type_stats_table.simulation_id == sim_id)

    # Create based on the entity_type_query a pandas DataFrame
    entity_type_df = pd.DataFrame(list(entity_type_query.dicts()))

    if entity_type_df.empty:
        logging.warning("No entity_type stats found.")
        return simulation_df

    # Transorm the pd.dataframe into a pivot_table with entity_types as columns
    pivot_entity_types = entity_type_df.pivot_table(
        index=["component_type", "component_name", "stat"],
        columns="entity_type",
        values="value",
        aggfunc="mean"
    ).reset_index()

    # Merge the simulation df with the entity_type pivot_table
    merged_pivot_table = pd.merge(
        simulation_df,
        pivot_entity_types,
        how="left",
        left_on=["type", "name", "stat"],
        right_on=["component_type", "component_name", "stat"]
    )

    # Remove redundant columns from the right table after the merge
    merged_pivot_table.drop(columns=["component_type", "component_name"], inplace=True)

    return merged_pivot_table


def create_etype_table(merged_df):
    """
    Creates a table based on the merged_pivot_table
    """
    num_etypes = len(EntityManager.entity_types_list)
    COLALIGN = ["left", "left", "left", "right"] + ["right"] * num_etypes

    if merged_df.empty:
        logging.error("No data to display.")
        return

    ignore_cols = {"simulation_id", "date", "time"}

    previous_row = {col: None for col in ["type", "name", "stat"]}
    tabulate_data = []

    for row in merged_df.itertuples(index=False):
        row_dict = row._asdict()

        if previous_row["type"] is not None and getattr(row, "type") != previous_row["type"]:
            tabulate_data.append(["__DIVIDER__"])

        value = row_dict["value"]
        suffix = " min" if any(key in row_dict["stat"] for key in tc.TIME_KEYWORDS) else ""
        formatted_value = f"{round(value, 4)}{suffix}" if pd.notnull(value) else ""

        row_data = [
            row_dict["type"] if row_dict["type"] != previous_row["type"] else "",
            row_dict["name"] if row_dict["name"] != previous_row["name"] else "",
            row_dict["stat"] if row_dict["stat"] != previous_row["stat"] else "",
            formatted_value
        ]

        entity_type_values = []
        for col in merged_df.columns:
            if col in {"type", "name", "stat", "value"} or col in ignore_cols:
                continue

            val = row_dict.get(col, "")
            if pd.notnull(val):
                suffix = " min" if any(key in row_dict["stat"] for key in tc.TIME_KEYWORDS) else ""
                formatted_val = f"{round(val, 4)}{suffix}"
            else:
                formatted_val = ""

            entity_type_values.append(formatted_val)
        row_data += entity_type_values

        tabulate_data.append(row_data)

        # Update Tracker
        previous_row["type"] = row_dict["type"]
        previous_row["name"] = row_dict["name"]
        previous_row["stat"] = row_dict["stat"]

    # Create headers dynamically
    headers = ["Type", "Name", "Stat", "Value"] + [
        col for col in merged_df.columns
        if col not in {"type", "name", "stat", "value"} | ignore_cols
    ]

    raw_table = tabulate(tabulate_data, headers=headers, tablefmt=tc.TABLE_FORMAT, colalign=COLALIGN)

    lines = raw_table.splitlines()
    dividing_lines = tc.inject_dividers(lines)

    final_table = "\n".join(dividing_lines)

    print(final_table)
